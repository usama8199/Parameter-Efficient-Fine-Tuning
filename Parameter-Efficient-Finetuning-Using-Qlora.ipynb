{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoRA (Low-Rank Adaptation) and QLoRA (Quantized Low-Rank Adaptation)** are techniques used to adapt large pre-trained models, such as those in natural language processing (NLP) and computer vision, with the aim of improving their performance on specific tasks while minimizing the number of parameters that need to be updated during fine-tuning. These methods are particularly valuable for efficiently customizing large models without the computational and memory overhead typically associated with training or fine-tuning such models.\n",
    "\n",
    "LoRA (Low-Rank Adaptation)\n",
    "LoRA focuses on adapting the weights of the pre-trained model in a low-rank subspace. Instead of updating all parameters of the model, LoRA identifies and updates a small subset of parameters, significantly reducing the computational cost and memory usage during fine-tuning. This approach is based on the observation that the effect of adapting a model can often be captured by adjusting only a small number of parameters.\n",
    "The key idea behind LoRA is to decompose certain weight matrices in the model into low-rank matrices. For example, consider a weight matrix W in a transformer model. LoRA would approximate adjustments to W using two smaller matrices A and B (where AB.T is the low-rank approximation), rather than directly modifying W. During fine-tuning, only A and B are learned, while W remains fixed. This low-rank approximation significantly reduces the number of trainable parameters.\n",
    "\n",
    "QLoRA (Quantized Low-Rank Adaptation)\n",
    "Building on the principles of LoRA, QLoRA introduces quantization into the low-rank adaptation process to further reduce the computational and memory requirements. Quantization is a technique that reduces the precision of the model's parameters, effectively allowing the model to operate with lower-precision arithmetic. This can lead to further efficiency improvements, particularly in deployment scenarios where computational resources are limited.\n",
    "\n",
    "QLoRA applies quantization to the matrices A and B in the low-rank approximation. By reducing the precision of these matrices, QLoRA decreases the amount of memory required to store them and the computational cost of using them during inference. This makes QLoRA an attractive option for deploying fine-tuned models to resource-constrained environments, such as mobile devices or embedded systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee88c68",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "This notebook demonstrates the process of fine-tuning a pre-trained model for the task of text summarization using Qlora. You can find the detail paper [here](https://arxiv.org/pdf/2305.14314.pdf). A little detail about qlora form paper is it backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters (LoRA). QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimizers to manage memory spikes. It is an updated version of [LoRA paper](https://arxiv.org/pdf/2106.09685.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used LLama2-7b with QLoRA (4 bit quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27b328b9-5af0-4780-8b5d-832abecec136",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015dab20",
   "metadata": {},
   "source": [
    "\n",
    "## Installation Instructions\n",
    "Before we start, it's essential to install all required Python packages and libraries. This includes `transformers` for leveraging state-of-the-art NLP models, `torch` for model training and operations, and other utility libraries like `accelerate` and `optimum` for optimizing training processes. Optional installations are noted; these might be necessary for specific environments or extended functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f66f9a75-d11f-439f-bc4d-dea00f71f8b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-10 12:23:32,074] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.34.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "987f0021-9c7e-407d-a6d9-4e2ca62f5e47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44e309a-d3b0-4d0d-8fed-0b97d84df1ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip uninstall torch\n",
    "#pip install torch>=2.0\n",
    "#pip install torch-utils\n",
    "#pip install pip --upgrade\n",
    "#pip install CUDA==11.6\n",
    "#pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a694c54-dce4-4441-b6cd-0738647fc7a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 10 12:41:58 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\r\n",
      "|  0%   24C    P0              58W / 300W |  21664MiB / 23028MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4755bf4-4817-4c43-8e57-6caea6a77caf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install flash-attn==1.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6559c1-e703-4443-917d-bcbebc177a91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install flash_attn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f54fbcc-7515-41d4-87e9-717688d1b031",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0ff3231-1828-4db4-b803-7f85a1879a83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7080bfd-5c12-429d-b940-8da3814d2ba6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install optimum --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c81219b1-3c3b-44d1-a6e0-4e4b34d7d4e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip3 install -U --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d133dab",
   "metadata": {},
   "source": [
    "\n",
    "## Data Preparation\n",
    "We use the \"Salesforce/dialogstudio\" dataset, specifically the \"TweetSumm\" version, for our text summarization task. This section covers the steps for loading the dataset, inspecting its structure, and preprocessing the data to make it suitable for training and inference. This includes tokenization and formatting inputs according to the requirements of the pre-trained model we aim to fine-tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3337b23-c97b-49bd-999c-e97cbd01d708",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16602f2-5d78-4bca-91c8-63a731c7b77f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687bccd1-7735-4625-a6ec-73956c99fadb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Preparing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970d4b5d-8098-4fcb-b579-2636a7b51d0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "import transformers\n",
    "#from llama_attn_replace import replace_llama_attn\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "OUTPUT_DIR = \"output_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f68038b-de80-4a60-9b50-5a8b30d398ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#replace_llama_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87cea46-5e31-4f85-a122-369cdf0568c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110c1f426fd456ea4e8eb5d50f6a3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/18.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221cd3f0d22048a9b99795b8f9a33e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce158b1f-8d2e-4ee0-bad7-e395c08f3600",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_training_prompt(\n",
    "    conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"[INST] <<SYS>> ###Instruction: {system_prompt} <</SYS>>\n",
    "\n",
    "### Input:\n",
    "{conversation.strip()}\n",
    "\n",
    "### Response: [/INST] \n",
    "{summary}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7417a207-dc91-429e-b5ec-740f6035b262",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "\n",
    "\n",
    "def create_conversation_text(data_point):\n",
    "    text = \"\"\n",
    "    for item in data_point[\"log\"]:\n",
    "        user = clean_text(item[\"user utterance\"])\n",
    "        text += f\"user: {user.strip()}\\n\"\n",
    "\n",
    "        agent = clean_text(item[\"system response\"])\n",
    "        text += f\"agent: {agent.strip()}\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da29599-a417-42ae-9da2-c744922b4377",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(data_point):\n",
    "    summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\n",
    "        \"abstractive_summaries\"\n",
    "    ]\n",
    "    summary = summaries[0]\n",
    "    summary = \" \".join(summary)\n",
    "\n",
    "    conversation_text = create_conversation_text(data_point)\n",
    "    return {\n",
    "        \"conversation\": conversation_text,\n",
    "        \"summary\": summary,\n",
    "        \"text\": generate_training_prompt(conversation_text, summary),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0f7edc2-3e89-405e-88b2-a9a69f449797",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': 'user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\\nagent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\nuser: My iPhone is on 11.1.2, and my watch is on 4.1.\\nagent: Thank you. Have you tried restarting both devices since this started happening?\\nuser: I’ve restarted both, also un-paired then re-paired the watch.\\nagent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\nuser: Yes, everything seems fine, it’s just Health and activity.\\nagent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\\n',\n",
       " 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.',\n",
       " 'text': '[INST] <<SYS>> ###Instruction: Below is a conversation between a human and an AI agent. Write a summary of the conversation. <</SYS>>\\n\\n### Input:\\nuser: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\\nagent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\nuser: My iPhone is on 11.1.2, and my watch is on 4.1.\\nagent: Thank you. Have you tried restarting both devices since this started happening?\\nuser: I’ve restarted both, also un-paired then re-paired the watch.\\nagent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\nuser: Yes, everything seems fine, it’s just Health and activity.\\nagent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\\n\\n### Response: [/INST] \\nCustomer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "example = generate_text(dataset[\"train\"][0])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db74363d-8bc2-40e1-a422-dc5ee9078b31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.\n"
     ]
    }
   ],
   "source": [
    "print(example[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2715c1e6-3d28-41a3-8e3c-2e4e2cfe3c4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\n",
      "agent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\n",
      "user: My iPhone is on 11.1.2, and my watch is on 4.1.\n",
      "agent: Thank you. Have you tried restarting both devices since this started happening?\n",
      "user: I’ve restarted both, also un-paired then re-paired the watch.\n",
      "agent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\n",
      "user: Yes, everything seems fine, it’s just Health and activity.\n",
      "agent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(example[\"conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab4ae29-1fbd-44e1-8cf5-11fe620a6c60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>> ###Instruction: Below is a conversation between a human and an AI agent. Write a summary of the conversation. <</SYS>>\n",
      "\n",
      "### Input:\n",
      "user: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? please read the above.\n",
      "agent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\n",
      "user: My iPhone is on 11.1.2, and my watch is on 4.1.\n",
      "agent: Thank you. Have you tried restarting both devices since this started happening?\n",
      "user: I’ve restarted both, also un-paired then re-paired the watch.\n",
      "agent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\n",
      "user: Yes, everything seems fine, it’s just Health and activity.\n",
      "agent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app?\n",
      "\n",
      "### Response: [/INST] \n",
      "Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.\n"
     ]
    }
   ],
   "source": [
    "print(example[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c41e6e7d-a9d1-4587-9f75-cf0490114758",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_text)\n",
    "        .remove_columns(\n",
    "            [\n",
    "                \"original dialog id\",\n",
    "                \"new dialog id\",\n",
    "                \"dialog index\",\n",
    "                \"original dialog info\",\n",
    "                \"log\",\n",
    "                \"prompt\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5aeef90-d99c-4a31-bb73-b4d14df75fda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e2854f5-07b0-4f43-8f4a-5a2e4ef073d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "449c7a3f-71df-4437-9714-845d67329cfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec9ab19-cb2a-4836-abd1-3e4b9eb21b3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e75ee1a51504006aa2b0379f425f540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01630d2e-dbda-4305-a9ce-50d8c3849cb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        use_flash_attention_2=True\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,use_fast=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6f630c6-85f8-4b3b-bc43-d8169574958b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a2da51db0d4ff08beda39533427a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad1e490702342f790a0091bd5620d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7d1f21d1a14cb68e986a151a0c2f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2b93314c204496830112850679150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f1192dfc894b85ba38b5799b897afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6553ff5c080496f925cc0f7b19b39a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cef6cb8552405689e9bbf4de952e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c541df978a48ccaac5519b6ccfd001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2447050d8c0e401c9cdbf75fd61a584f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8cb32c32b34c5f9047fc1a5098a6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca752efc03544d5a9172763ff2953109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = create_model_and_tokenizer()\n",
    "model.config.use_cache = False\n",
    "#model = model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77ec09fc-dc1e-49d1-abbd-964f2783106e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "198efd99-fb16-44d7-b1e8-b21bec859e59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7c2298-0159-4e5c-a6c7-9aef3cc75478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir save_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d503fdc-261f-4968-8495-62443bf257b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95709d56-3423-4cf8-9209-40273ac7ad9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.25,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf559d6-4478-4596-8c53-22eae52ec0f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#pip install pyarrow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9168d7e-4af7-4e97-9d80-188d80c3623f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea81501b-40ff-43c4-bb1b-ff695b43ea74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18977\n"
     ]
    }
   ],
   "source": [
    "words=[word for sentence in dataset[\"train\"][\"text\"] for word in sentence.split()]\n",
    "\n",
    "# Get the set of unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Print the number of unique words\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7749842f-0301-4bff-bfea-017a6b9ad69c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4607\n"
     ]
    }
   ],
   "source": [
    "words=[word for sentence in dataset[\"validation\"][\"text\"] for word in sentence.split()]\n",
    "\n",
    "# Get the set of unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Print the number of unique words\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f10db65-bfe9-4f64-8445-a1f41b58bbba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 39,976,960 || all params: 6,778,392,576 || trainable%: 0.589770503135875\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trainer.model.print_trainable_parameters())\n",
    "\n",
    "\n",
    "# # Get the trainable parameters\n",
    "# trainable_parameters = [name for name, param in trainer.model.named_parameters() if param.requires_grad]\n",
    "\n",
    "# # Print the trainable parameters\n",
    "# print(len(trainable_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd72d80-0fd4-4a48-ab35-fec0117785f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['conversation', 'summary', 'text'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fbf7027-f766-41e7-8ea7-f4834622ee5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for name, module in trainer.model.named_modules():\n",
    "#   if \"norm\" in name:\n",
    "#     module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c5ec977-58d7-455c-9b51-415208af2009",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=int(942*(1/4))\n",
    "942%a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab9c1f21-61bf-43dd-bb57-fe2d753b7123",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e744b1-9ca1-40dd-857d-c729bc9cac5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Command took 49.29 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c246686-a3e5-4d89-8851-56e28bb9897d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#trainer.save_model(\"your_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af1d960-249c-4d80-8266-d569448e6d4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cda55f7-03e1-4a33-9252-c544947a66fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f044dd0-2db8-419e-bbf2-423402a59ef4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_prompt(\n",
    "    conversation: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"[INST] <<SYS>> ###Instruction: {system_prompt}  <</SYS>> \n",
    "\n",
    "### Input:\n",
    "{conversation.strip()}\n",
    "\n",
    "### Response: [/INST] \n",
    "\"\"\".strip()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a69b3ede-2112-42ff-b780-e61acdca225a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#! pip install pyarrow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7446b9-2e05-4d34-8437-47d8fdfa2de0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>conversation</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer is complaining that the watchlist is ...</td>\n",
       "      <td>user: My watchlist is not updating with new ep...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt; ###Instruction: Below is a conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer is asking about the ACC to link to th...</td>\n",
       "      <td>user: hi , my Acc was linked to an old number....</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt; ###Instruction: Below is a conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer is complaining about the new updates ...</td>\n",
       "      <td>user: the new update ios11 sucks. I can’t even...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt; ###Instruction: Below is a conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer is complaining about parcel service  ...</td>\n",
       "      <td>user: FUCK YOU AND YOUR SHITTY PARCEL SERVICE ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt; ###Instruction: Below is a conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The customer says that he is stuck at Staines ...</td>\n",
       "      <td>user: Stuck at Staines waiting for a Reading t...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt; ###Instruction: Below is a conv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  ...                                             prompt\n",
       "0  Customer is complaining that the watchlist is ...  ...  [INST] <<SYS>> ###Instruction: Below is a conv...\n",
       "1  Customer is asking about the ACC to link to th...  ...  [INST] <<SYS>> ###Instruction: Below is a conv...\n",
       "2  Customer is complaining about the new updates ...  ...  [INST] <<SYS>> ###Instruction: Below is a conv...\n",
       "3  Customer is complaining about parcel service  ...  ...  [INST] <<SYS>> ###Instruction: Below is a conv...\n",
       "4  The customer says that he is stuck at Staines ...  ...  [INST] <<SYS>> ###Instruction: Below is a conv...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = []\n",
    "for data_point in dataset[\"test\"].select(range(5)):\n",
    "    summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\n",
    "        \"abstractive_summaries\"\n",
    "    ]\n",
    "    summary = summaries[0]\n",
    "    summary = \" \".join(summary)\n",
    "    conversation = create_conversation_text(data_point)\n",
    "    examples.append(\n",
    "        {\n",
    "            \"summary\": summary,\n",
    "            \"conversation\": conversation,\n",
    "            \"prompt\": generate_prompt(conversation),\n",
    "        }\n",
    "    )\n",
    "test_df = pd.DataFrame(examples)\n",
    "test_df\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c01f1573-3d65-4eb0-b54c-573d43bca973",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarize(model, text: str):\n",
    "    #print(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    print(inputs)\n",
    "    print(inputs_length)\n",
    "    #with torch.inference_mode():\n",
    "    with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.1)\n",
    "    #print(outputs)\n",
    "\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3a268d-896d-474d-86b0-d47a754c4dce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        #use_flash_attention_2=True\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,use_fast=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd43c58a-6581-46ec-aade-378892528e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Eample 1 (Not-FineTuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f13473-1bff-4a63-898c-104fde00ccbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#replace_llama_attn(inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "160feded-53a2-4109-96bf-7d7e5fb610d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4c532898b1480a970c62a037cd21d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe02cdb1ac544cd8816218fcfca433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eae2f6dbb14eb3a1ed72bf23db0693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed36b8f5892743e190862e3fd9e3fc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b65c9579a44478928be0610f0e1e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5363dc74589245ad96b02adda442d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdbe05edbd945d598473e970d25ebe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41826ed46e814018bd34d6682692086c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f2663f0664412da2e0c20bbeb99a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab4e116b5a6472488a53d3b7bd8468b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f6b42dc35485f95d9bea604e20afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_nottuned, tokenizer = create_model_and_tokenizer()\n",
    "model_nottuned.config.use_cache = False\n",
    "#model_nottuned.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508a7320-f570-40fa-b510-22cb95174058",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model_nottuned_main=model_nottuned.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79772b05-eb30-4353-a2c1-e62d8e7b344b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"quantization_config\": {\n",
       "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": false,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nottuned.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3be944dc-60ea-4083-b282-1d9b66a79cc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: My watchlist is not updating with new episodes (past couple days). Any idea why?\n",
      "agent: Apologies for the trouble, Norlene! We're looking into this. In the meantime, try navigating to the season / episode manually.\n",
      "user: Tried logging out/back in, that didn’t help\n",
      "agent: Sorry! 😔 We assure you that our team is working hard to investigate, and we hope to have a fix ready soon!\n",
      "user: Thank you! Some shows updated overnight, but others did not...\n",
      "agent: We definitely understand, Norlene. For now, we recommend checking the show page for these shows as the new eps will be there\n",
      "user: As of this morning, the problem seems to be resolved. Watchlist updated overnight with all new episodes. Thank you for your attention to this matter! I love Hulu 💚\n",
      "agent: Awesome! That's what we love to hear. If you happen to need anything else, we'll be here to support! 💚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = test_df.iloc[0]\n",
    "print(example.conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1592f470-0cfc-4747-a11b-dca39b9e8169",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer is complaining that the watchlist is not updated with new episodes from past two days. Agent informed that the team is working hard to investigate to show new episodes on page.\n"
     ]
    }
   ],
   "source": [
    "print(example.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0680b081-e7b6-43e2-8a4b-da131663ea59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST] <<SYS>> ###Instruction: Below is a conversation between a human and an AI agent. Write a summary of the conversation.  <</SYS>> \\n\\n### Input:\\nuser: My watchlist is not updating with new episodes (past couple days). Any idea why?\\nagent: Apologies for the trouble, Norlene! We're looking into this. In the meantime, try navigating to the season / episode manually.\\nuser: Tried logging out/back in, that didn’t help\\nagent: Sorry! 😔 We assure you that our team is working hard to investigate, and we hope to have a fix ready soon!\\nuser: Thank you! Some shows updated overnight, but others did not...\\nagent: We definitely understand, Norlene. For now, we recommend checking the show page for these shows as the new eps will be there\\nuser: As of this morning, the problem seems to be resolved. Watchlist updated overnight with all new episodes. Thank you for your attention to this matter! I love Hulu 💚\\nagent: Awesome! That's what we love to hear. If you happen to need anything else, we'll be here to support! 💚\\n\\n### Response: [/INST]\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1be07d9d-62c9-4b80-8903-929a29d1f4d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,   835,  3379,\n",
      "          4080, 29901, 13866,   338,   263, 14983,  1546,   263,  5199,   322,\n",
      "           385,   319, 29902, 10823, 29889, 14350,   263, 15837,   310,   278,\n",
      "         14983, 29889, 29871,   529,   829, 14816, 29903,  6778, 29871,    13,\n",
      "            13,  2277, 29937, 10567, 29901,    13,  1792, 29901,  1619,  6505,\n",
      "          1761,   338,   451, 13271,   411,   716, 23238,   313, 29886,   579,\n",
      "          7303,  3841,   467,  3139,  2969,  2020, 29973,    13, 14748, 29901,\n",
      "          6225, 11763,   363,   278,  7458, 29892,  4186, 29880,  1600, 29991,\n",
      "          1334, 29915,   276,  3063,   964,   445, 29889,   512,   278,  6839,\n",
      "           603, 29892,  1018, 12402,  1218,   304,   278,  4259,   847, 12720,\n",
      "          7522, 29889,    13,  1792, 29901, 29547, 12183,   714, 29914,  1627,\n",
      "           297, 29892,   393,  3282, 30010, 29873,  1371,    13, 14748, 29901,\n",
      "          8221, 29991, 29871,   243,   162,   155,   151,  1334,  1223,   545,\n",
      "           366,   393,  1749,  3815,   338,  1985,  2898,   304, 23033, 29892,\n",
      "           322,   591,  4966,   304,   505,   263,  2329,  7960,  4720, 29991,\n",
      "            13,  1792, 29901,  3374,   366, 29991,  3834,  3697,  4784,   975,\n",
      "         11147, 29892,   541,  4045,  1258,   451,   856,    13, 14748, 29901,\n",
      "          1334, 11630,  2274, 29892,  4186, 29880,  1600, 29889,  1152,  1286,\n",
      "         29892,   591,  6907,  8454,   278,  1510,  1813,   363,  1438,  3697,\n",
      "           408,   278,   716,   321,   567,   674,   367,   727,    13,  1792,\n",
      "         29901,  1094,   310,   445,  7250, 29892,   278,  1108,  2444,   304,\n",
      "           367, 11527, 29889, 24274,  1761,  4784,   975, 11147,   411,   599,\n",
      "           716, 23238, 29889,  3374,   366,   363,   596,  8570,   304,   445,\n",
      "          4383, 29991,   306,  5360,   379, 21528, 29871,   243,   162,   149,\n",
      "           157,    13, 14748, 29901, 22886, 14151, 29991,  2193, 29915, 29879,\n",
      "           825,   591,  5360,   304,  8293, 29889,   960,   366,  3799,   304,\n",
      "           817,  3099,  1683, 29892,   591, 29915,   645,   367,  1244,   304,\n",
      "          2304, 29991, 29871,   243,   162,   149,   157,    13,    13,  2277,\n",
      "         29937, 13291, 29901,   518, 29914, 25580, 29962]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n",
      "287\n",
      "CPU times: user 16.4 s, sys: 436 ms, total: 16.8 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_nottuned.to_bettertransformer()\n",
    "summary = summarize(model_nottuned, example.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50bd6b7b-6756-4f47-88e5-d865a60eb3eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '\\n'\n",
      " '### Output:\\n'\n",
      " '<</SYS>>\\n'\n",
      " '\\n'\n",
      " '### Explanation:\\n'\n",
      " '\\n'\n",
      " '### Input:\\n'\n",
      " 'user: My watchlist is not updating with new episodes (past couple days). Any '\n",
      " 'idea why?\\n'\n",
      " \"agent: Apologies for the trouble, Norlene! We're looking into this. In the \"\n",
      " 'meantime, try navigating to the season / episode manually.\\n'\n",
      " 'user: Tried logging out/back in, that didn’t help\\n'\n",
      " 'agent: Sorry! 😔 We assure you that our team is working hard to investigate, '\n",
      " 'and we hope to have a fix ready soon!\\n'\n",
      " 'user: Thank you! Some shows updated overnight, but others did not...\\n'\n",
      " 'agent: We definitely understand, Norlene. For now, we recommend checking the '\n",
      " 'show page for these shows as the new eps will be there\\n'\n",
      " 'user: As of this morning, the problem seems to be resolved. Watchlist '\n",
      " 'updated overnight with all new episodes. Thank you for your attention to '\n",
      " 'this matter! I love Hulu 💚\\n'\n",
      " \"agent: Awesome! That's what we love to hear. If you happen to need anything \"\n",
      " \"else, we'll be here to support! ��\")\n"
     ]
    }
   ],
   "source": [
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a71f984f-e2ab-4b9c-8378-6a84d8750797",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Eample 1 (FineTuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed30bec-c2da-404b-943e-cc67c8b0a2ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#enable_flash=True, enable_math=False, enable_mem_efficient=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a036fe6d-67bc-4879-a5ab-f76db818ad4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install optimum --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e285c38-2153-4e7d-8f38-644c6b7c4bd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#model_nottuned.to_bettertransformer()\n",
    "model_tuned = PeftModel.from_pretrained(model_nottuned,\"save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49063e3-572f-4d81-89d1-510472e33b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,   835,  3379,\n",
      "          4080, 29901, 13866,   338,   263, 14983,  1546,   263,  5199,   322,\n",
      "           385,   319, 29902, 10823, 29889, 14350,   263, 15837,   310,   278,\n",
      "         14983, 29889, 29871,   529,   829, 14816, 29903,  6778, 29871,    13,\n",
      "            13,  2277, 29937, 10567, 29901,    13,  1792, 29901,  1619,  6505,\n",
      "          1761,   338,   451, 13271,   411,   716, 23238,   313, 29886,   579,\n",
      "          7303,  3841,   467,  3139,  2969,  2020, 29973,    13, 14748, 29901,\n",
      "          6225, 11763,   363,   278,  7458, 29892,  4186, 29880,  1600, 29991,\n",
      "          1334, 29915,   276,  3063,   964,   445, 29889,   512,   278,  6839,\n",
      "           603, 29892,  1018, 12402,  1218,   304,   278,  4259,   847, 12720,\n",
      "          7522, 29889,    13,  1792, 29901, 29547, 12183,   714, 29914,  1627,\n",
      "           297, 29892,   393,  3282, 30010, 29873,  1371,    13, 14748, 29901,\n",
      "          8221, 29991, 29871,   243,   162,   155,   151,  1334,  1223,   545,\n",
      "           366,   393,  1749,  3815,   338,  1985,  2898,   304, 23033, 29892,\n",
      "           322,   591,  4966,   304,   505,   263,  2329,  7960,  4720, 29991,\n",
      "            13,  1792, 29901,  3374,   366, 29991,  3834,  3697,  4784,   975,\n",
      "         11147, 29892,   541,  4045,  1258,   451,   856,    13, 14748, 29901,\n",
      "          1334, 11630,  2274, 29892,  4186, 29880,  1600, 29889,  1152,  1286,\n",
      "         29892,   591,  6907,  8454,   278,  1510,  1813,   363,  1438,  3697,\n",
      "           408,   278,   716,   321,   567,   674,   367,   727,    13,  1792,\n",
      "         29901,  1094,   310,   445,  7250, 29892,   278,  1108,  2444,   304,\n",
      "           367, 11527, 29889, 24274,  1761,  4784,   975, 11147,   411,   599,\n",
      "           716, 23238, 29889,  3374,   366,   363,   596,  8570,   304,   445,\n",
      "          4383, 29991,   306,  5360,   379, 21528, 29871,   243,   162,   149,\n",
      "           157,    13, 14748, 29901, 22886, 14151, 29991,  2193, 29915, 29879,\n",
      "           825,   591,  5360,   304,  8293, 29889,   960,   366,  3799,   304,\n",
      "           817,  3099,  1683, 29892,   591, 29915,   645,   367,  1244,   304,\n",
      "          2304, 29991, 29871,   243,   162,   149,   157,    13,    13,  2277,\n",
      "         29937, 13291, 29901,   518, 29914, 25580, 29962]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n",
      "287\n",
      "CPU times: user 23.2 s, sys: 479 ms, total: 23.7 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summary = summarize(model_tuned, example.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f34cbbe4-b970-45f2-9782-9da5339d1d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf5ab4af-669f-4fe5-9007-fa531525fbb9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Instruction**\\\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation\n",
    "\n",
    "**Discussion**\\\n",
    "user: My watchlist is not updating with new episodes (past couple days). Any idea why?\\\n",
    "agent: Apologies for the trouble, Norlene! We're looking into this. In the meantime, try navigating to the season / episode manually.\\\n",
    "user: Tried logging out/back in, that didn’t help\\\n",
    "agent: Sorry! 😔 We assure you that our team is working hard to investigate, and we hope to have a fix ready soon!\\\n",
    "user: Thank you! Some shows updated overnight, but others did not...\\\n",
    "agent: We definitely understand, Norlene. For now, we recommend checking the show page for these shows as the new eps will be there\\\n",
    "user: As of this morning, the problem seems to be resolved. Watchlist updated overnight with all new episodes. Thank you for your attention to this matter! I love Hulu 💚\\\n",
    "agent: Awesome! That's what we love to hear. If you happen to need anything else, we'll be here to support! 💚\n",
    "\n",
    "\n",
    "\n",
    "**Actual Summary**\\\n",
    "Customer is complaining that the watchlist is not updated with new episodes from past two days. Agent informed that the team is working hard to investigate to show new episodes on page.\n",
    "\n",
    "**Not-FinedTuned Summary**\\\n",
    "user: My watchlist is not updating with new episodes (past couple days). Any '\n",
    " 'idea why?\\n'\n",
    " \"agent: Apologies for the trouble, Norlene! We're looking into this. In the \"\n",
    " 'meantime, try navigating to the season / episode manually.\\n'\n",
    " 'user: Tried logging out/back in, that didn’t help\\n'\n",
    " 'agent: Sorry! 😔 We assure you that our team is working hard to investigate, '\n",
    " 'and we hope to have a fix ready soon!\\n'\n",
    " 'user: Thank you! Some shows updated overnight, but others did not...\\n'\n",
    " 'agent: We definitely understand, Norlene. For now, we recommend checking the '\n",
    " 'show page for these shows as the new eps will be there\\n'\n",
    " 'user: As of this morning, the problem seems to be resolved. Watchlist '\n",
    " 'updated overnight with all new episodes. Thank you for your attention to '\n",
    " 'this matter! I love Hulu 💚\\n'\n",
    " \"agent: Awesome! That's what we love to hear. If you happen to need anything \"\n",
    " \"else, we'll be here to support! 💚\\n\"\n",
    "\n",
    " **Fined Tuned Summary**\\\n",
    " 'Customer is complaining that his watchlist is not updating with new episodes. Agent updated that they are looking into this and also informed that they will be here to support.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "663f74a6-9f99-4ee4-847d-1f57ae9e6e10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Instruction**\\\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation\n",
    "\n",
    "**Discussion**\\\n",
    "user: hi , my Acc was linked to an old number. Now I’m asked to verify my Acc , where a code / call wil be sent to my old number. Any way that I can link my Acc to my current number? Pls help\\\n",
    "agent: Hi there, we are here to help. We will have a specialist contact you about changing your phone number. Thank you.\\\n",
    "user: Thanks. Hope to get in touch soon\\\n",
    "agent: That is no problem. Please let us know if you have any further questions in the meantime.\\\n",
    "user: Hi sorry , is it for my account : __email__\\\n",
    "agent: Can you please delete this post as it does have personal info in it. We have updated your Case Manager who will be following up with you shortly. Feel free to DM us anytime with any other questions or concerns 2/2\\\n",
    "user: Thank you\\\n",
    "agent: That is no problem. Please do not hesitate to contact us with any further questions. Thank you.\\\n",
    "\n",
    "\n",
    "\n",
    "**Actual Summary**\\\n",
    "Customer is asking about the ACC to link to the current  number. Agent says that they have updated their case manager.\n",
    "\n",
    "**Not-FinedTuned Summary**\\\n",
    "'\\n'\n",
    " 'The conversation between a human and an AI agent is about changing the phone '\n",
    " 'number of an account. The human asks if there is any way to link the account '\n",
    " 'to a new phone number, and the agent replies that they will have a '\n",
    " 'specialist contact the user about changing the phone number. The human '\n",
    " 'thanks the agent and hopes to get in touch soon. The agent then asks the '\n",
    " 'human to delete the post as it contains personal information. The human '\n",
    " 'replies that they will delete the post. The agent then thanks the human for '\n",
    " 'their cooperation and closes the conversation.\\n'\n",
    " '\\n'\n",
    " '### Output:\\n'\n",
    "\n",
    " **Fined Tuned Summary**\\\n",
    "'Customer is asking to link his account to his current number. Agent updated '\n",
    " 'that they will have a specialist contact him about changing his phone '\n",
    " 'number.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b77ad149-8cd2-4fdd-9767-54f5cc74b69d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Parameter:** \\\n",
    " trainable params: 39,976,960 || all params: 6,778,392,576 || trainable%: 0.589770503135875\n",
    "\n",
    "**Computation Summary** :\\\n",
    "Worker Type: g4dn.xlarge(16GB Memory 1GPU) 2-8 Workers\\\n",
    "Driver Type: g4dn.xlarge(16GB Memory 1GPU)\n",
    "\n",
    "**Time Took to train**\n",
    "49 Minutes\n",
    "\n",
    "**Unique Tokens**\n",
    "25k Tokens\n",
    "\n",
    "**Non-Unique Tokens**\n",
    "250k Tokens\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1235124321000414,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Fine-Tuning Using Peft-QLora",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
